{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ea3c629-ffd7-48f6-9ff1-96a43d120c9f",
   "metadata": {},
   "source": [
    "# Reproduction of the TrAdaBoost experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aedc081-d6af-45dc-a9e1-bcd71e83f90b",
   "metadata": {},
   "source": [
    "<div class=\"btn btn-notebook\" role=\"button\">\n",
    "    <img src=\"../_static/images/github_logo_32px.png\"> [View on GitHub](https://github.com/adapt-python/adapt/blob/master/src_docs/examples/tradaboost_experiments.ipynb)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22504a0-5ff7-498e-bc35-a6c101926204",
   "metadata": {},
   "source": [
    "The purpose of this example is to reproduce the results obtained in the paper [Boosting for Transfer Learning (2007)](https://cse.hkust.edu.hk/~qyang/Docs/2007/tradaboost.pdf). In this work, the authors developed a transfer algorithm called TrAdaBoost dedicated for [supervised domain adaptation](https://adapt-python.github.io/adapt/map.html). You can find more details about this algorithm [here](https://adapt-python.github.io/adapt/generated/adapt.instance_based.TrAdaBoost.html). The goal of this algorithm is to combine a source dataset with many labeled instances to a target dataset with few labels in order to learn a good model on the target domain.\n",
    "\n",
    "We try to reproduce the two following exepriments:\n",
    "\n",
    "- Mushrooms\n",
    "- 20newsgroups\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8858843-a9c6-4057-b0b4-98fd54f78446",
   "metadata": {},
   "source": [
    "## Mushrooms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f53ff99-7e5a-4ca0-aa33-621892658db8",
   "metadata": {},
   "source": [
    "**Dataset description** The [Mushrooms](https://archive.ics.uci.edu/ml/datasets/mushroom) data set includes descriptions of hypothetical samples corresponding to 23 species of gilled mushrooms in the Agaricus and Lepiota Family (pp. 500-525). Each species is identified as definitely edible, definitely poisonous, or of unknown edibility and not recommended. This latter class was combined with the poisonous one. The Guide clearly states that there is no simple rule for determining the edibility of a mushroom."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff93112-2296-437f-9b7e-6f06cf106ad5",
   "metadata": {},
   "source": [
    "**Experiment description**: For the TrAdaBoost experiment, according to the authors :\n",
    "\n",
    "> The data is splited in two sets based on the feature *stalk-shape*. The diff-distribution data set (*the source data set*) consists of all the instances whose stalks are **enlarging**, while the same-distribution data set (*the target data set*) consists\n",
    "of the instances about **tapering** mushrooms. Then, the two sets contain examples from different types of mushrooms, which makes the distributions different.\n",
    "> -- <cite>Boosting for Transfer Learning (2007)</cite>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "188423ec-8c78-4279-a0f3-fbfcb240c6f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from adapt.datasets import open_uci_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "44b5d350-bef9-4b86-9c7b-435362485f85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cap-shape</th>\n",
       "      <th>cap-surface</th>\n",
       "      <th>cap-color</th>\n",
       "      <th>bruises?</th>\n",
       "      <th>odor</th>\n",
       "      <th>gill-attachment</th>\n",
       "      <th>gill-spacing</th>\n",
       "      <th>gill-size</th>\n",
       "      <th>gill-color</th>\n",
       "      <th>stalk-shape</th>\n",
       "      <th>...</th>\n",
       "      <th>stalk-surface-below-ring</th>\n",
       "      <th>stalk-color-above-ring</th>\n",
       "      <th>stalk-color-below-ring</th>\n",
       "      <th>veil-type</th>\n",
       "      <th>veil-color</th>\n",
       "      <th>ring-number</th>\n",
       "      <th>ring-type</th>\n",
       "      <th>spore-print-color</th>\n",
       "      <th>population</th>\n",
       "      <th>habitat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>n</td>\n",
       "      <td>t</td>\n",
       "      <td>p</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>k</td>\n",
       "      <td>e</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>k</td>\n",
       "      <td>s</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>y</td>\n",
       "      <td>t</td>\n",
       "      <td>a</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>k</td>\n",
       "      <td>e</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>t</td>\n",
       "      <td>l</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>e</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>x</td>\n",
       "      <td>y</td>\n",
       "      <td>w</td>\n",
       "      <td>t</td>\n",
       "      <td>p</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>e</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>k</td>\n",
       "      <td>s</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>g</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>w</td>\n",
       "      <td>b</td>\n",
       "      <td>k</td>\n",
       "      <td>t</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>a</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  cap-shape cap-surface cap-color bruises? odor gill-attachment gill-spacing  \\\n",
       "0         x           s         n        t    p               f            c   \n",
       "1         x           s         y        t    a               f            c   \n",
       "2         b           s         w        t    l               f            c   \n",
       "3         x           y         w        t    p               f            c   \n",
       "4         x           s         g        f    n               f            w   \n",
       "\n",
       "  gill-size gill-color stalk-shape  ... stalk-surface-below-ring  \\\n",
       "0         n          k           e  ...                        s   \n",
       "1         b          k           e  ...                        s   \n",
       "2         b          n           e  ...                        s   \n",
       "3         n          n           e  ...                        s   \n",
       "4         b          k           t  ...                        s   \n",
       "\n",
       "  stalk-color-above-ring stalk-color-below-ring veil-type veil-color  \\\n",
       "0                      w                      w         p          w   \n",
       "1                      w                      w         p          w   \n",
       "2                      w                      w         p          w   \n",
       "3                      w                      w         p          w   \n",
       "4                      w                      w         p          w   \n",
       "\n",
       "  ring-number ring-type spore-print-color population habitat  \n",
       "0           o         p                 k          s       u  \n",
       "1           o         p                 n          n       g  \n",
       "2           o         p                 n          n       m  \n",
       "3           o         p                 k          s       u  \n",
       "4           o         e                 n          a       g  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/mushroom/agaricus-lepiota.data\"\n",
    "columns = [\"target\", \"cap-shape\",\"cap-surface\",\"cap-color\",\"bruises?\",\"odor\",\"gill-attachment\",\"gill-spacing\",\n",
    "           \"gill-size\",\"gill-color\",\"stalk-shape\",\"stalk-root\",\"stalk-surface-above-ring\",\"stalk-surface-below-ring\",\n",
    "           \"stalk-color-above-ring\",\"stalk-color-below-ring\",\"veil-type\",\"veil-color\",\"ring-number\",\"ring-type\",\n",
    "           \"spore-print-color\",\"population\",\"habitat\"]\n",
    "data = pd.read_csv(url, header=None)\n",
    "data.columns = columns\n",
    "X = data.drop([\"target\"], axis=1)\n",
    "y = data[[\"target\"]]\n",
    "display(X.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "78914a0a-9536-41e3-bafc-f4c2cb58dad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "t    4608\n",
       "e    3516\n",
       "Name: stalk-shape, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[\"stalk-shape\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9013a30c-6193-4ac4-a977-cdf5a97206cf",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "**Note:** When looking at the number of instances in each category of the *stalk-shape* attribute, it seems that the authors inversed the source data set with the target one in the text above. Indeed, when looking at Table 1 in the paper, the number of source instances should be 4608 which corresponds to the **tapering** class and not the **enlarging** one.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d457afbc-93cb-4601-bf24-e38681a31139",
   "metadata": {},
   "source": [
    "For the first experiment, the number of traget instances is set to 1% of the length of the source data set:\n",
    "\n",
    "> Each same-distribution (*understand \"target\"*) data set is split into two sets: a same-distribution training set Ts and a test set S. Table\n",
    "3 presents the experimental results of **SVM**, **SVMt**, **AUX** and **TrAdaBoost(SVM)** when the ratio between same-distribution and diff-distribution (*understand \"source\"*) training data is 0.01. The performance in error rate was the average of 10 repeats by random. The number of iterations (*of TrAdaBoost*) is set to 100.\n",
    "> -- <cite>Boosting for Transfer Learning (2007)</cite>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db328190-f32f-4b19-848b-885e64b9b37a",
   "metadata": {},
   "source": [
    "Here **SVM** refers to a linear SVM classifier fitted only with source data, **SVMt** with source and target labeled data whith uniform weight, **AUX** refers to the BalanceWeighting method and **TrAdaBoost(SVM)** to TrAdaBoost used with a linear SVM classifier as base-learner. We also add a comparison with AdaBoost to verify that TrAdaBoost is not advantaged by the averaging of predicition over multiple estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ebd2aef1-bba8-45b9-a821-718786a09d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_source_target(X, y, ratio_of_target_labels=0.01):\n",
    "\n",
    "    Xs = X.loc[X[\"stalk-shape\"]==\"t\"]\n",
    "    ys = y.loc[Xs.index]\n",
    "    Xt = X.loc[X[\"stalk-shape\"]==\"e\"]\n",
    "    yt = y.loc[Xt.index]\n",
    "\n",
    "    Xt_lab = Xt.sample(int(ratio_of_target_labels*len(Xs)))\n",
    "    yt_lab = yt.loc[Xt_lab.index]\n",
    "    \n",
    "    Xt = Xt.drop(Xt_lab.index, axis=0)\n",
    "    yt = yt.drop(yt_lab.index, axis=0)\n",
    "    \n",
    "    ohe = OneHotEncoder(sparse=False).fit(X)\n",
    "    Xs = ohe.transform(Xs)\n",
    "    Xt = ohe.transform(Xt)\n",
    "    Xt_lab = ohe.transform(Xt_lab)\n",
    "\n",
    "    return Xs, ys[\"target\"], Xt, yt[\"target\"], Xt_lab, yt_lab[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d7a8353d-5f79-4969-9053-ef61cce865e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from adapt.base import BaseAdaptEstimator\n",
    "from scipy.sparse import vstack, issparse\n",
    "\n",
    "# We create here the AUX model which consist in a balanced weighting\n",
    "# between instances from source and target domains.\n",
    "class BalancedWeighting(BaseAdaptEstimator):\n",
    "    \n",
    "    def __init__(self, estimator=None, alpha=1., Xt=None, yt=None):\n",
    "        super().__init__(estimator=estimator, alpha=alpha, Xt=Xt, yt=yt)\n",
    "    \n",
    "    def fit(self, Xs, ys, Xt=None, yt=None, **kwargs):\n",
    "        Xt, yt = self._get_target_data(Xt, yt)\n",
    "        if issparse(Xs):\n",
    "            X = vstack((Xs, Xt))\n",
    "        else:\n",
    "            X = np.concatenate((Xs, Xt))\n",
    "        y = np.concatenate((ys, yt))\n",
    "        sample_weight = np.ones(X.shape[0])\n",
    "        sample_weight[Xs.shape[0]:] *= (Xs.shape[0] / Xt.shape[0]) * self.alpha\n",
    "        \n",
    "        self.fit_estimator(X, y, sample_weight=sample_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041d95a8-dfaf-476d-94f8-218b69daef4e",
   "metadata": {},
   "source": [
    "We repeat the experiment 10 times with different random seed, the trade-off parameter alpha for the Balanced Weighting technique (AUX) is set to 4 as did the authors:\n",
    "\n",
    "> Besides the baselines, we also compare TrAdaBoost with the method developed for learning with auxiliary data proposed by Wu and Dietterich (2004), which is denoted as AUX. The parameter Cp/Ca (as used in (Wu & Dietterich, 2004)) is set to 4 after tuning.\n",
    "> -- <cite>Boosting for Transfer Learning (2007)</cite>\n",
    "\n",
    "Besides, we balanced the weights between positive and negative instances:\n",
    "\n",
    "> Furthermore, we also added some constraints to the basic learners to avoid the case of training weights being unbalanced. When training SVM, we always balance the overall training weights between positive and negative examples.\n",
    "> -- <cite>Boosting for Transfer Learning (2007)</cite>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e6752425-9c73-4e68-a7f3-770cb034b64e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xs shape: (4608, 117), Xt shape: (3470, 117)\n",
      "Round 0 : {'SVM': 0.262, 'SVMt': 0.069, 'AUX': 0.067, 'TrAdaBoost': 0.067}\n",
      "Round 1 : {'SVM': 0.263, 'SVMt': 0.06, 'AUX': 0.062, 'TrAdaBoost': 0.061}\n",
      "Round 2 : {'SVM': 0.262, 'SVMt': 0.045, 'AUX': 0.046, 'TrAdaBoost': 0.048}\n",
      "Round 3 : {'SVM': 0.261, 'SVMt': 0.021, 'AUX': 0.017, 'TrAdaBoost': 0.028}\n",
      "Round 4 : {'SVM': 0.262, 'SVMt': 0.049, 'AUX': 0.048, 'TrAdaBoost': 0.052}\n",
      "Round 5 : {'SVM': 0.261, 'SVMt': 0.052, 'AUX': 0.052, 'TrAdaBoost': 0.052}\n",
      "Round 6 : {'SVM': 0.261, 'SVMt': 0.08, 'AUX': 0.08, 'TrAdaBoost': 0.063}\n",
      "Round 7 : {'SVM': 0.262, 'SVMt': 0.086, 'AUX': 0.086, 'TrAdaBoost': 0.082}\n",
      "Round 8 : {'SVM': 0.263, 'SVMt': 0.048, 'AUX': 0.049, 'TrAdaBoost': 0.044}\n",
      "Round 9 : {'SVM': 0.261, 'SVMt': 0.042, 'AUX': 0.042, 'TrAdaBoost': 0.031}\n"
     ]
    }
   ],
   "source": [
    "from adapt.instance_based import TrAdaBoost\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "names = [\"SVM\", \"SVMt\", \"AUX\", \"TrAdaBoost\"]\n",
    "\n",
    "scores = {k: [] for k in names}\n",
    "\n",
    "for state in range(10):\n",
    "    \n",
    "    np.random.seed(state)\n",
    "    \n",
    "    Xs, ys, Xt, yt, Xt_lab, yt_lab = split_source_target(X, y, ratio_of_target_labels=0.01)\n",
    "    \n",
    "    if state == 0:\n",
    "        print(\"Xs shape: %s, Xt shape: %s\"%(str(Xs.shape), str(Xt.shape)))\n",
    "\n",
    "    models = [\n",
    "        LinearSVC(class_weight=\"balanced\"),\n",
    "        LinearSVC(class_weight=\"balanced\"),\n",
    "        BalancedWeighting(LinearSVC(class_weight=\"balanced\"), alpha=4., Xt=Xt_lab, yt=yt_lab),\n",
    "        TrAdaBoost(LinearSVC(class_weight=\"balanced\"), n_estimators=100, verbose=0, Xt=Xt_lab, yt=yt_lab)\n",
    "    ]\n",
    "\n",
    "    for model, name in zip(models, names):\n",
    "        \n",
    "        if name == \"SVMt\":\n",
    "            model.fit(np.concatenate((Xs, Xt_lab)), np.concatenate((ys, yt_lab)))\n",
    "        else:\n",
    "            model.fit(Xs, ys)\n",
    "        scores[name].append(1-model.score(Xt, yt))\n",
    "    \n",
    "    print(\"Round %i : %s\"%(state, str({k: np.round(v[-1], 3) for k, v in scores.items()})))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6cc3d8-3c2a-4cf1-9792-e47985cab481",
   "metadata": {},
   "source": [
    "### Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f745cb7f-4796-4e86-b255-9d5f1fcaeab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SVM</th>\n",
       "      <th>SVMt</th>\n",
       "      <th>AUX</th>\n",
       "      <th>TrAdaBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Error</th>\n",
       "      <td>0.261 (0.001)</td>\n",
       "      <td>0.055 (0.019)</td>\n",
       "      <td>0.055 (0.02)</td>\n",
       "      <td>0.053 (0.016)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 SVM           SVMt           AUX     TrAdaBoost\n",
       "Error  0.261 (0.001)  0.055 (0.019)  0.055 (0.02)  0.053 (0.016)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "error_mu = np.round(pd.DataFrame(pd.DataFrame(scores).mean(0), columns=[\"Error\"]), 3).transpose().astype(str)\n",
    "error_std = np.round(pd.DataFrame(pd.DataFrame(scores).std(0), columns=[\"Error\"]), 3).transpose().astype(str)\n",
    "display(error_mu + \" (\" + error_std + \")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd4c5d6-54db-416f-8394-a96a2c11af81",
   "metadata": {},
   "source": [
    "The results that we obtain differ a little from the ones obtained by the authors in Table 3. Here, the error for SVMt, AUX and TrAdaBoost is smaller but the error of SVM is higher. Moreover, the error of SVMt is much lower than the corresponding error computed by the authors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "babd1cce-c39e-4516-9a10-9d7e9f00f190",
   "metadata": {},
   "source": [
    "## 20 NewsGroup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77af17ab-60e2-49d7-90fa-4cba5cfb39df",
   "metadata": {},
   "source": [
    "**Dataset description** The [20 NewsGroup](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_20newsgroups.html) data set comprises around 18000 newsgroups posts on 20 main topics, whith some topics divided in subcategories.\n",
    "\n",
    "**Experiment description** For the TrAdaBoost experiment, according to the authors:\n",
    ">We define the tasks as top-category classification problems. When we split the data to generate diff-distribution (source) and same-distribution (target) sets, the data are split based on subcategories instead of based on random splitting. Then, the two data sets contain data in different subcategories. Their distributions also differ as a result.\n",
    "> -- <cite>Boosting for Transfer Learning (2007)</cite>\n",
    "\n",
    "The authors do not precise which categories have been selected whithin each domain. We try to impute them based on the number of instances in each domain given by the authors in Table 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "872479cd-06e0-4efb-a5b3-da589b139636",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# Set download_if_missing to True if not downloaded yet\n",
    "data = fetch_20newsgroups(download_if_missing=False, subset=\"all\")\n",
    "\n",
    "source_rec = ['rec.autos', 'rec.motorcycles']\n",
    "target_rec = ['rec.sport.baseball', 'rec.sport.hockey']\n",
    "source_sci = ['sci.crypt', 'sci.electronics']\n",
    "target_sci = ['sci.med', 'sci.space']\n",
    "source_talk = ['talk.politics.guns', 'talk.politics.mideast']\n",
    "target_talk = ['talk.politics.misc', 'talk.religion.misc']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831e0467-41cc-4096-84d5-1424a64cb441",
   "metadata": {},
   "source": [
    "The author do not precise which preprocessing is applied on the data, so we use the default preprocessing of scikit-learn: TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "17317618-3b6a-4497-8544-392c27b12eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words=\"english\",\n",
    "                                 analyzer=\"word\",\n",
    "                                 min_df=5,\n",
    "                                 max_df=0.1)\n",
    "    \n",
    "X = vectorizer.fit_transform(data.data)\n",
    "\n",
    "def split_source_target(source_index, target_index, positive_index, ratio_of_target_labels=0.01):\n",
    "    \n",
    "    Xs = X[source_index]\n",
    "    Xt = X[target_index]\n",
    "    \n",
    "    ys = np.isin(data.target[source_index], positive_index).astype(float)\n",
    "    yt = np.isin(data.target[target_index], positive_index).astype(float)\n",
    "\n",
    "    lab_index = np.random.choice(Xt.shape[0], int(0.01*Xs.shape[0]), replace=False)\n",
    "    unlab_index = np.array(list(set(np.arange(Xt.shape[0]))-set(lab_index)))\n",
    "    \n",
    "    Xt_lab = Xt[lab_index]\n",
    "    yt_lab = yt[lab_index]\n",
    "    \n",
    "    Xt = Xt[unlab_index]\n",
    "    yt = yt[unlab_index]\n",
    "\n",
    "    return Xs, ys, Xt, yt, Xt_lab, yt_lab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b660c8-67d0-4427-91b7-fe75efe676c5",
   "metadata": {},
   "source": [
    "We conduct the three proposed experiments \"rec vs talk\", \"rec vs sci\" and \"sci vs talk\". We set the number of TrAdaBoost estimators to 10 instead of 100. We found that using 100 estimators give poor results for TrAdaBoost."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054fa3be-c83e-4c64-a3ff-58c51ea397fe",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Rec vs talk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1f791e3f-3433-476d-a14b-7078f65f778d",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_rec = ['rec.autos', 'rec.motorcycles']\n",
    "target_rec = ['rec.sport.baseball', 'rec.sport.hockey']\n",
    "source_talk = ['talk.politics.guns', 'talk.politics.misc']\n",
    "target_talk = ['talk.religion.misc', 'talk.politics.mideast']\n",
    "\n",
    "source_index = np.isin(data.target, [data.target_names.index(s) for s in source_rec+source_talk])\n",
    "target_index = np.isin(data.target, [data.target_names.index(s) for s in target_rec+target_talk])\n",
    "positive_index = [data.target_names.index(s) for s in target_rec+source_rec]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fdb35389-5908-4762-8248-6b6c6b895e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xs shape: (3671, 34814), Xt shape: (3525, 34814)\n",
      "Round 0 : {'SVM': 0.206, 'SVMt': 0.112, 'AUX': 0.099, 'TrAdaBoost': 0.091}\n",
      "Round 1 : {'SVM': 0.207, 'SVMt': 0.106, 'AUX': 0.085, 'TrAdaBoost': 0.076}\n",
      "Round 2 : {'SVM': 0.206, 'SVMt': 0.107, 'AUX': 0.089, 'TrAdaBoost': 0.076}\n",
      "Round 3 : {'SVM': 0.205, 'SVMt': 0.119, 'AUX': 0.1, 'TrAdaBoost': 0.084}\n",
      "Round 4 : {'SVM': 0.205, 'SVMt': 0.092, 'AUX': 0.08, 'TrAdaBoost': 0.078}\n",
      "Round 5 : {'SVM': 0.205, 'SVMt': 0.107, 'AUX': 0.089, 'TrAdaBoost': 0.081}\n",
      "Round 6 : {'SVM': 0.205, 'SVMt': 0.106, 'AUX': 0.087, 'TrAdaBoost': 0.076}\n",
      "Round 7 : {'SVM': 0.207, 'SVMt': 0.104, 'AUX': 0.089, 'TrAdaBoost': 0.081}\n",
      "Round 8 : {'SVM': 0.207, 'SVMt': 0.104, 'AUX': 0.092, 'TrAdaBoost': 0.091}\n",
      "Round 9 : {'SVM': 0.206, 'SVMt': 0.104, 'AUX': 0.088, 'TrAdaBoost': 0.073}\n"
     ]
    }
   ],
   "source": [
    "from adapt.instance_based import TrAdaBoost\n",
    "from sklearn.svm import LinearSVC\n",
    "from scipy.sparse import vstack\n",
    "\n",
    "names = [\"SVM\", \"SVMt\", \"AUX\", \"TrAdaBoost\"]\n",
    "\n",
    "scores = {k: [] for k in names}\n",
    "\n",
    "for state in range(10):\n",
    "    \n",
    "    np.random.seed(state)\n",
    "    \n",
    "    Xs, ys, Xt, yt, Xt_lab, yt_lab = split_source_target(source_index,\n",
    "                                                         target_index,\n",
    "                                                         positive_index,\n",
    "                                                         ratio_of_target_labels=0.01)\n",
    "    if state == 0:\n",
    "        print(\"Xs shape: %s, Xt shape: %s\"%(str(Xs.shape), str(Xt.shape)))\n",
    "\n",
    "    models = [\n",
    "        LinearSVC(class_weight=\"balanced\"),\n",
    "        LinearSVC(class_weight=\"balanced\"),\n",
    "        BalancedWeighting(LinearSVC(class_weight=\"balanced\"), alpha=4., Xt=Xt_lab, yt=yt_lab),\n",
    "        TrAdaBoost(LinearSVC(class_weight=\"balanced\"), n_estimators=10, verbose=0, Xt=Xt_lab, yt=yt_lab)\n",
    "    ]\n",
    "\n",
    "    for model, name in zip(models, names):\n",
    "        \n",
    "        if name == \"SVMt\":\n",
    "            model.fit(vstack((Xs, Xt_lab)), np.concatenate((ys, yt_lab)))\n",
    "        else:\n",
    "            model.fit(Xs, ys)\n",
    "        scores[name].append(1-model.score(Xt, yt))\n",
    "    \n",
    "    print(\"Round %i : %s\"%(state, str({k: np.round(v[-1], 3) for k, v in scores.items()})))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83312007-17e3-40d1-838a-bc00c415dbd2",
   "metadata": {},
   "source": [
    "### Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7d00f3e4-1905-4066-92bc-82eaaf9f5064",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SVM</th>\n",
       "      <th>SVMt</th>\n",
       "      <th>AUX</th>\n",
       "      <th>TrAdaBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Error</th>\n",
       "      <td>0.206 (0.001)</td>\n",
       "      <td>0.106 (0.007)</td>\n",
       "      <td>0.09 (0.006)</td>\n",
       "      <td>0.081 (0.006)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 SVM           SVMt           AUX     TrAdaBoost\n",
       "Error  0.206 (0.001)  0.106 (0.007)  0.09 (0.006)  0.081 (0.006)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "error_mu = np.round(pd.DataFrame(pd.DataFrame(scores).mean(0), columns=[\"Error\"]), 3).transpose().astype(str)\n",
    "error_std = np.round(pd.DataFrame(pd.DataFrame(scores).std(0), columns=[\"Error\"]), 3).transpose().astype(str)\n",
    "display(error_mu + \" (\" + error_std + \")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92475d1e-5cc1-4143-9182-501aff3723cb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Rec vs Sci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3c88b9d9-9e0c-4554-9bc8-ac989dc508cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_rec = ['rec.autos', 'rec.motorcycles']\n",
    "target_rec = ['rec.sport.baseball', 'rec.sport.hockey']\n",
    "source_sci = ['sci.crypt', 'sci.electronics']\n",
    "target_sci = ['sci.med', 'sci.space']\n",
    "\n",
    "source_index = np.isin(data.target, [data.target_names.index(s) for s in source_sci+source_rec])\n",
    "target_index = np.isin(data.target, [data.target_names.index(s) for s in target_sci+target_rec])\n",
    "positive_index = [data.target_names.index(s) for s in target_rec+source_rec]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "378ae882-340c-427d-afce-90c21f74c11b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xs shape: (3961, 34814), Xt shape: (3931, 34814)\n",
      "Round 0 : {'SVM': 0.347, 'SVMt': 0.194, 'AUX': 0.16, 'TrAdaBoost': 0.131}\n",
      "Round 1 : {'SVM': 0.347, 'SVMt': 0.17, 'AUX': 0.14, 'TrAdaBoost': 0.116}\n",
      "Round 2 : {'SVM': 0.349, 'SVMt': 0.208, 'AUX': 0.177, 'TrAdaBoost': 0.144}\n",
      "Round 3 : {'SVM': 0.347, 'SVMt': 0.163, 'AUX': 0.139, 'TrAdaBoost': 0.119}\n",
      "Round 4 : {'SVM': 0.346, 'SVMt': 0.165, 'AUX': 0.137, 'TrAdaBoost': 0.115}\n",
      "Round 5 : {'SVM': 0.349, 'SVMt': 0.205, 'AUX': 0.163, 'TrAdaBoost': 0.138}\n",
      "Round 6 : {'SVM': 0.347, 'SVMt': 0.166, 'AUX': 0.14, 'TrAdaBoost': 0.121}\n",
      "Round 7 : {'SVM': 0.349, 'SVMt': 0.22, 'AUX': 0.182, 'TrAdaBoost': 0.15}\n",
      "Round 8 : {'SVM': 0.35, 'SVMt': 0.185, 'AUX': 0.153, 'TrAdaBoost': 0.115}\n",
      "Round 9 : {'SVM': 0.349, 'SVMt': 0.205, 'AUX': 0.169, 'TrAdaBoost': 0.139}\n"
     ]
    }
   ],
   "source": [
    "from adapt.instance_based import TrAdaBoost\n",
    "from sklearn.svm import LinearSVC\n",
    "from scipy.sparse import vstack\n",
    "\n",
    "names = [\"SVM\", \"SVMt\", \"AUX\", \"TrAdaBoost\"]\n",
    "\n",
    "scores = {k: [] for k in names}\n",
    "\n",
    "for state in range(10):\n",
    "    \n",
    "    np.random.seed(state)\n",
    "    \n",
    "    Xs, ys, Xt, yt, Xt_lab, yt_lab = split_source_target(source_index,\n",
    "                                                         target_index,\n",
    "                                                         positive_index,\n",
    "                                                         ratio_of_target_labels=0.01)\n",
    "    if state == 0:\n",
    "        print(\"Xs shape: %s, Xt shape: %s\"%(str(Xs.shape), str(Xt.shape)))\n",
    "\n",
    "    models = [\n",
    "        LinearSVC(class_weight=\"balanced\"),\n",
    "        LinearSVC(class_weight=\"balanced\"),\n",
    "        BalancedWeighting(LinearSVC(class_weight=\"balanced\"), alpha=4., Xt=Xt_lab, yt=yt_lab),\n",
    "        TrAdaBoost(LinearSVC(class_weight=\"balanced\"), n_estimators=10, verbose=0, Xt=Xt_lab, yt=yt_lab)\n",
    "    ]\n",
    "\n",
    "    for model, name in zip(models, names):\n",
    "        \n",
    "        if name == \"SVMt\":\n",
    "            model.fit(vstack((Xs, Xt_lab)), np.concatenate((ys, yt_lab)))\n",
    "        else:\n",
    "            model.fit(Xs, ys)\n",
    "        scores[name].append(1-model.score(Xt, yt))\n",
    "    \n",
    "    print(\"Round %i : %s\"%(state, str({k: np.round(v[-1], 3) for k, v in scores.items()})))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc958679-d90f-4b05-8406-16ab0e35b0e6",
   "metadata": {},
   "source": [
    "### Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c15f5de0-b2b2-49d8-addd-4dbf097207a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SVM</th>\n",
       "      <th>SVMt</th>\n",
       "      <th>AUX</th>\n",
       "      <th>TrAdaBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Error</th>\n",
       "      <td>0.348 (0.001)</td>\n",
       "      <td>0.188 (0.021)</td>\n",
       "      <td>0.156 (0.017)</td>\n",
       "      <td>0.129 (0.013)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 SVM           SVMt            AUX     TrAdaBoost\n",
       "Error  0.348 (0.001)  0.188 (0.021)  0.156 (0.017)  0.129 (0.013)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "error_mu = np.round(pd.DataFrame(pd.DataFrame(scores).mean(0), columns=[\"Error\"]), 3).transpose().astype(str)\n",
    "error_std = np.round(pd.DataFrame(pd.DataFrame(scores).std(0), columns=[\"Error\"]), 3).transpose().astype(str)\n",
    "display(error_mu + \" (\" + error_std + \")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f506a4-52e3-4f33-8b00-c0b4a1d6bf44",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Talk vs Sci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "40c3caf0-b9ba-4219-8ef2-743df65be41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_sci = ['sci.crypt', 'sci.electronics']\n",
    "target_sci = ['sci.med', 'sci.space']\n",
    "source_talk = ['talk.politics.misc', 'talk.religion.misc']\n",
    "target_talk = ['talk.politics.guns', 'talk.politics.mideast']\n",
    "\n",
    "source_index = np.isin(data.target, [data.target_names.index(s) for s in source_sci+source_talk])\n",
    "target_index = np.isin(data.target, [data.target_names.index(s) for s in target_sci+target_talk])\n",
    "positive_index = [data.target_names.index(s) for s in target_sci+source_sci]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9988d294-906c-42a6-918f-999123e58d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xs shape: (3378, 34814), Xt shape: (3794, 34814)\n",
      "Round 0 : {'SVM': 0.261, 'SVMt': 0.209, 'AUX': 0.185, 'TrAdaBoost': 0.159}\n",
      "Round 1 : {'SVM': 0.26, 'SVMt': 0.218, 'AUX': 0.202, 'TrAdaBoost': 0.184}\n",
      "Round 2 : {'SVM': 0.26, 'SVMt': 0.203, 'AUX': 0.182, 'TrAdaBoost': 0.166}\n",
      "Round 3 : {'SVM': 0.26, 'SVMt': 0.214, 'AUX': 0.199, 'TrAdaBoost': 0.177}\n",
      "Round 4 : {'SVM': 0.26, 'SVMt': 0.197, 'AUX': 0.176, 'TrAdaBoost': 0.154}\n",
      "Round 5 : {'SVM': 0.261, 'SVMt': 0.214, 'AUX': 0.199, 'TrAdaBoost': 0.18}\n",
      "Round 6 : {'SVM': 0.26, 'SVMt': 0.202, 'AUX': 0.182, 'TrAdaBoost': 0.16}\n",
      "Round 7 : {'SVM': 0.26, 'SVMt': 0.202, 'AUX': 0.179, 'TrAdaBoost': 0.158}\n",
      "Round 8 : {'SVM': 0.259, 'SVMt': 0.186, 'AUX': 0.165, 'TrAdaBoost': 0.142}\n",
      "Round 9 : {'SVM': 0.26, 'SVMt': 0.192, 'AUX': 0.167, 'TrAdaBoost': 0.145}\n"
     ]
    }
   ],
   "source": [
    "from adapt.instance_based import TrAdaBoost\n",
    "from sklearn.svm import LinearSVC\n",
    "from scipy.sparse import vstack\n",
    "\n",
    "names = [\"SVM\", \"SVMt\", \"AUX\", \"TrAdaBoost\"]\n",
    "\n",
    "scores = {k: [] for k in names}\n",
    "\n",
    "for state in range(10):\n",
    "    \n",
    "    np.random.seed(state)\n",
    "    \n",
    "    Xs, ys, Xt, yt, Xt_lab, yt_lab = split_source_target(source_index,\n",
    "                                                         target_index,\n",
    "                                                         positive_index,\n",
    "                                                         ratio_of_target_labels=0.01)\n",
    "    if state == 0:\n",
    "        print(\"Xs shape: %s, Xt shape: %s\"%(str(Xs.shape), str(Xt.shape)))\n",
    "\n",
    "    models = [\n",
    "        LinearSVC(class_weight=\"balanced\"),\n",
    "        LinearSVC(class_weight=\"balanced\"),\n",
    "        BalancedWeighting(LinearSVC(class_weight=\"balanced\"), alpha=4., Xt=Xt_lab, yt=yt_lab),\n",
    "        TrAdaBoost(LinearSVC(class_weight=\"balanced\"), n_estimators=10, verbose=0, Xt=Xt_lab, yt=yt_lab)\n",
    "    ]\n",
    "\n",
    "    for model, name in zip(models, names):\n",
    "        \n",
    "        if name == \"SVMt\":\n",
    "            model.fit(vstack((Xs, Xt_lab)), np.concatenate((ys, yt_lab)))\n",
    "        else:\n",
    "            model.fit(Xs, ys)\n",
    "        scores[name].append(1-model.score(Xt, yt))\n",
    "    \n",
    "    print(\"Round %i : %s\"%(state, str({k: np.round(v[-1], 3) for k, v in scores.items()})))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0f5d98-08bb-438d-82a9-7b5af5db44b9",
   "metadata": {},
   "source": [
    "### Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2053dee5-4062-4b96-a8a1-39557c7d0626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SVM</th>\n",
       "      <th>SVMt</th>\n",
       "      <th>AUX</th>\n",
       "      <th>TrAdaBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Error</th>\n",
       "      <td>0.26 (0.0)</td>\n",
       "      <td>0.204 (0.01)</td>\n",
       "      <td>0.184 (0.013)</td>\n",
       "      <td>0.162 (0.014)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              SVM          SVMt            AUX     TrAdaBoost\n",
       "Error  0.26 (0.0)  0.204 (0.01)  0.184 (0.013)  0.162 (0.014)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "error_mu = np.round(pd.DataFrame(pd.DataFrame(scores).mean(0), columns=[\"Error\"]), 3).transpose().astype(str)\n",
    "error_std = np.round(pd.DataFrame(pd.DataFrame(scores).std(0), columns=[\"Error\"]), 3).transpose().astype(str)\n",
    "display(error_mu + \" (\" + error_std + \")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19eb0273-7c19-49ff-aa5b-8ddce2766e59",
   "metadata": {},
   "source": [
    "We can see that are not very similar to the ones that the authors obtained but we have the same hierarchical order of error level: SVM > SVMt > AUX > TrAdaBoost"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "statmath38",
   "language": "python",
   "name": "statmath38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
